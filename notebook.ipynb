{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mobile Legends : Bang Bang Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the Scrapped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewId</th>\n",
       "      <th>userName</th>\n",
       "      <th>userImage</th>\n",
       "      <th>content</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "      <th>appVersion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4a2755ef-8989-4908-97fe-ef8bc8a7bdc1</td>\n",
       "      <td>A Google user</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>Bad matching system for ranked games. Both sid...</td>\n",
       "      <td>1</td>\n",
       "      <td>2170</td>\n",
       "      <td>1.8.93.9702</td>\n",
       "      <td>2024-08-31 11:13:31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.8.93.9702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a9d7d176-323e-4231-a74a-e572986b9019</td>\n",
       "      <td>A Google user</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>I'm really disappointed with Mobile Legends' p...</td>\n",
       "      <td>1</td>\n",
       "      <td>242</td>\n",
       "      <td>1.9.47.10372</td>\n",
       "      <td>2025-02-26 21:52:54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.9.47.10372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>afc81f0f-ba6f-4cde-b458-185ad8c1d8ac</td>\n",
       "      <td>A Google user</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>If you want a MOBA game that is device friendl...</td>\n",
       "      <td>5</td>\n",
       "      <td>6064</td>\n",
       "      <td>1.9.48.10373</td>\n",
       "      <td>2025-03-03 21:01:22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.9.48.10373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5dbeda4b-93d1-47e2-943a-f2401d78debd</td>\n",
       "      <td>A Google user</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>I really love playing Brawl mode! I think it h...</td>\n",
       "      <td>4</td>\n",
       "      <td>489</td>\n",
       "      <td>1.9.47.10372</td>\n",
       "      <td>2025-02-14 17:09:57</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.9.47.10372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>eec29d50-e45c-4815-ba6f-8e5b5bb6ddde</td>\n",
       "      <td>A Google user</td>\n",
       "      <td>https://play-lh.googleusercontent.com/EGemoI2N...</td>\n",
       "      <td>Honestly the best moba game for mobile! the op...</td>\n",
       "      <td>5</td>\n",
       "      <td>700</td>\n",
       "      <td>1.9.48.10373</td>\n",
       "      <td>2025-03-17 12:21:10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.9.48.10373</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               reviewId       userName  \\\n",
       "0  4a2755ef-8989-4908-97fe-ef8bc8a7bdc1  A Google user   \n",
       "1  a9d7d176-323e-4231-a74a-e572986b9019  A Google user   \n",
       "2  afc81f0f-ba6f-4cde-b458-185ad8c1d8ac  A Google user   \n",
       "3  5dbeda4b-93d1-47e2-943a-f2401d78debd  A Google user   \n",
       "4  eec29d50-e45c-4815-ba6f-8e5b5bb6ddde  A Google user   \n",
       "\n",
       "                                           userImage  \\\n",
       "0  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "1  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "2  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "3  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "4  https://play-lh.googleusercontent.com/EGemoI2N...   \n",
       "\n",
       "                                             content  score  thumbsUpCount  \\\n",
       "0  Bad matching system for ranked games. Both sid...      1           2170   \n",
       "1  I'm really disappointed with Mobile Legends' p...      1            242   \n",
       "2  If you want a MOBA game that is device friendl...      5           6064   \n",
       "3  I really love playing Brawl mode! I think it h...      4            489   \n",
       "4  Honestly the best moba game for mobile! the op...      5            700   \n",
       "\n",
       "  reviewCreatedVersion                   at replyContent repliedAt  \\\n",
       "0          1.8.93.9702  2024-08-31 11:13:31          NaN       NaN   \n",
       "1         1.9.47.10372  2025-02-26 21:52:54          NaN       NaN   \n",
       "2         1.9.48.10373  2025-03-03 21:01:22          NaN       NaN   \n",
       "3         1.9.47.10372  2025-02-14 17:09:57          NaN       NaN   \n",
       "4         1.9.48.10373  2025-03-17 12:21:10          NaN       NaN   \n",
       "\n",
       "     appVersion  \n",
       "0   1.8.93.9702  \n",
       "1  1.9.47.10372  \n",
       "2  1.9.48.10373  \n",
       "3  1.9.47.10372  \n",
       "4  1.9.48.10373  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlbb_reviews = pd.read_csv('mlbb_reviews.csv')\n",
    "mlbb_reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 72000 entries, 0 to 71999\n",
      "Data columns (total 11 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   reviewId              72000 non-null  object\n",
      " 1   userName              72000 non-null  object\n",
      " 2   userImage             72000 non-null  object\n",
      " 3   content               72000 non-null  object\n",
      " 4   score                 72000 non-null  int64 \n",
      " 5   thumbsUpCount         72000 non-null  int64 \n",
      " 6   reviewCreatedVersion  57603 non-null  object\n",
      " 7   at                    72000 non-null  object\n",
      " 8   replyContent          1951 non-null   object\n",
      " 9   repliedAt             1951 non-null   object\n",
      " 10  appVersion            57603 non-null  object\n",
      "dtypes: int64(2), object(9)\n",
      "memory usage: 6.0+ MB\n"
     ]
    }
   ],
   "source": [
    "mlbb_reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Empty Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 57603 entries, 0 to 71999\n",
      "Data columns (total 9 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   reviewId              57603 non-null  object\n",
      " 1   userName              57603 non-null  object\n",
      " 2   userImage             57603 non-null  object\n",
      " 3   content               57603 non-null  object\n",
      " 4   score                 57603 non-null  int64 \n",
      " 5   thumbsUpCount         57603 non-null  int64 \n",
      " 6   reviewCreatedVersion  57603 non-null  object\n",
      " 7   at                    57603 non-null  object\n",
      " 8   appVersion            57603 non-null  object\n",
      "dtypes: int64(2), object(7)\n",
      "memory usage: 4.4+ MB\n"
     ]
    }
   ],
   "source": [
    "mlbb_reviews = mlbb_reviews.drop(columns=['replyContent', 'repliedAt'])\n",
    "mlbb_reviews = mlbb_reviews.dropna()\n",
    "mlbb_reviews.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preproccessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/felixwilimz/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /Users/felixwilimz/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/felixwilimz/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "import string \n",
    "import nltk  # Import pustaka NLTK (Natural Language Toolkit).\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('punkt', force=True) \n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords') \n",
    "\n",
    "def cleaningText(text):\n",
    "    text = re.sub(r'@[A-Za-z0-9]+', '', text) # menghapus mention\n",
    "    text = re.sub(r'#[A-Za-z0-9]+', '', text) # menghapus hashtag\n",
    "    text = re.sub(r'RT[\\s]', '', text) # menghapus RT\n",
    "    text = re.sub(r\"http\\S+\", '', text) # menghapus link\n",
    "    text = re.sub(r'[0-9]+', '', text) # menghapus angka\n",
    "    text = re.sub(r'[^\\w\\s]', '', text) # menghapus karakter selain huruf dan angka\n",
    " \n",
    "    text = text.replace('\\n', ' ') # mengganti baris baru dengan spasi\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation)) # menghapus semua tanda baca\n",
    "    text = text.strip(' ') # menghapus karakter spasi dari kiri dan kanan teks\n",
    "    return text\n",
    " \n",
    "def casefoldingText(text): # Mengubah semua karakter dalam teks menjadi huruf kecil\n",
    "    text = text.lower()\n",
    "    return text\n",
    " \n",
    "def tokenizingText(text): # Memecah atau membagi string, teks menjadi daftar token\n",
    "    text = word_tokenize(text)\n",
    "    return text\n",
    " \n",
    "def filteringText(text): # Menghapus stopwords dalam teks\n",
    "    listStopwords = set(stopwords.words('indonesian'))\n",
    "    listStopwords1 = set(stopwords.words('english'))\n",
    "    listStopwords.update(listStopwords1)\n",
    "    listStopwords.update(['iya','yaa','gak','nya','na','sih','ku',\"di\",\"ga\",\"ya\",\"gaa\",\"loh\",\"kah\",\"woi\",\"woii\",\"woy\"])\n",
    "    filtered = []\n",
    "    for txt in text:\n",
    "        if txt not in listStopwords:\n",
    "            filtered.append(txt)\n",
    "    text = filtered\n",
    "    return text\n",
    "\n",
    "def stemmingText(text):\n",
    "    ps = PorterStemmer()\n",
    "    words = text.split()\n",
    "    stemmed_words = [ps.stem(word) for word in words]\n",
    "    stemmed_text = ' '.join(stemmed_words)\n",
    "    return stemmed_text\n",
    "    \n",
    "    \n",
    "\n",
    " \n",
    "def toSentence(list_words): # Mengubah daftar kata menjadi kalimat\n",
    "    sentence = ' '.join(word for word in list_words)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlbb_reviews['text_clean'] = mlbb_reviews['content'].apply(cleaningText)\n",
    "\n",
    "mlbb_reviews['text_casefoldingText'] = mlbb_reviews['text_clean'].apply(casefoldingText)\n",
    "\n",
    "mlbb_reviews['text_tokenizingText'] = mlbb_reviews['text_casefoldingText'].apply(tokenizingText)\n",
    "\n",
    "mlbb_reviews['text_stopword'] = mlbb_reviews['text_tokenizingText'].apply(filteringText)\n",
    "\n",
    "mlbb_reviews['final_text'] = mlbb_reviews['text_stopword'].apply(toSentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/felixwilimz/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def get_sentiment(text):\n",
    "    scores = analyzer.polarity_scores(text)\n",
    "    sentiment = 1 if scores['pos'] > 0 else 0 \n",
    "    return sentiment \n",
    "\n",
    "\n",
    "mlbb_reviews['sentiment'] = mlbb_reviews['final_text'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account</th>\n",
       "      <th>afk</th>\n",
       "      <th>almost</th>\n",
       "      <th>already</th>\n",
       "      <th>also</th>\n",
       "      <th>always</th>\n",
       "      <th>annoying</th>\n",
       "      <th>another</th>\n",
       "      <th>anymore</th>\n",
       "      <th>app</th>\n",
       "      <th>...</th>\n",
       "      <th>wifi</th>\n",
       "      <th>win</th>\n",
       "      <th>without</th>\n",
       "      <th>wont</th>\n",
       "      <th>work</th>\n",
       "      <th>worse</th>\n",
       "      <th>worst</th>\n",
       "      <th>would</th>\n",
       "      <th>years</th>\n",
       "      <th>youre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.501784</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.26674</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.229215</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.157526</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.154682</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.191829</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.219878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.147898</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153381</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.221435</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57598</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.295263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57599</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.196263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57600</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57601</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57602</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>57603 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       account       afk    almost  already      also    always  annoying  \\\n",
       "0          0.0  0.000000  0.000000      0.0  0.000000  0.501784       0.0   \n",
       "1          0.0  0.000000  0.229215      0.0  0.157526  0.000000       0.0   \n",
       "2          0.0  0.000000  0.000000      0.0  0.154682  0.000000       0.0   \n",
       "3          0.0  0.147898  0.000000      0.0  0.000000  0.000000       0.0   \n",
       "4          0.0  0.000000  0.000000      0.0  0.221435  0.000000       0.0   \n",
       "...        ...       ...       ...      ...       ...       ...       ...   \n",
       "57598      0.0  0.000000  0.000000      0.0  0.000000  0.000000       0.0   \n",
       "57599      0.0  0.000000  0.000000      0.0  0.000000  0.000000       0.0   \n",
       "57600      0.0  0.000000  0.000000      0.0  0.000000  0.000000       0.0   \n",
       "57601      0.0  0.000000  0.000000      0.0  0.000000  0.000000       0.0   \n",
       "57602      0.0  0.000000  0.000000      0.0  0.000000  0.000000       0.0   \n",
       "\n",
       "       another  anymore  app  ...  wifi       win   without  wont      work  \\\n",
       "0      0.26674      0.0  0.0  ...   0.0  0.000000  0.000000   0.0  0.000000   \n",
       "1      0.00000      0.0  0.0  ...   0.0  0.000000  0.000000   0.0  0.000000   \n",
       "2      0.00000      0.0  0.0  ...   0.0  0.191829  0.000000   0.0  0.219878   \n",
       "3      0.00000      0.0  0.0  ...   0.0  0.000000  0.000000   0.0  0.000000   \n",
       "4      0.00000      0.0  0.0  ...   0.0  0.000000  0.000000   0.0  0.000000   \n",
       "...        ...      ...  ...  ...   ...       ...       ...   ...       ...   \n",
       "57598  0.00000      0.0  0.0  ...   0.0  0.000000  0.295263   0.0  0.000000   \n",
       "57599  0.00000      0.0  0.0  ...   0.0  0.000000  0.000000   0.0  0.000000   \n",
       "57600  0.00000      0.0  0.0  ...   0.0  0.000000  0.000000   0.0  0.000000   \n",
       "57601  0.00000      0.0  0.0  ...   0.0  0.000000  0.000000   0.0  0.000000   \n",
       "57602  0.00000      0.0  0.0  ...   0.0  0.000000  0.000000   0.0  0.000000   \n",
       "\n",
       "       worse  worst     would  years  youre  \n",
       "0        0.0    0.0  0.000000    0.0    0.0  \n",
       "1        0.0    0.0  0.000000    0.0    0.0  \n",
       "2        0.0    0.0  0.000000    0.0    0.0  \n",
       "3        0.0    0.0  0.153381    0.0    0.0  \n",
       "4        0.0    0.0  0.000000    0.0    0.0  \n",
       "...      ...    ...       ...    ...    ...  \n",
       "57598    0.0    0.0  0.000000    0.0    0.0  \n",
       "57599    0.0    0.0  0.196263    0.0    0.0  \n",
       "57600    0.0    0.0  0.000000    0.0    0.0  \n",
       "57601    0.0    0.0  0.000000    0.0    0.0  \n",
       "57602    0.0    0.0  0.000000    0.0    0.0  \n",
       "\n",
       "[57603 rows x 200 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = mlbb_reviews['final_text']\n",
    "y = mlbb_reviews['sentiment']\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=200, min_df=17, max_df=0.8, stop_words=None)\n",
    "X_tfidf = tfidf.fit_transform(X)\n",
    "\n",
    "features_df = pd.DataFrame(X_tfidf.toarray(), columns=tfidf.get_feature_names_out())\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "features_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9381971268608134\n",
      "Test Accuracy: 0.940543355611492\n",
      "F1 Score: 0.968220830433774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.62      0.54       648\n",
      "           1       0.98      0.96      0.97     10873\n",
      "\n",
      "    accuracy                           0.94     11521\n",
      "   macro avg       0.73      0.79      0.75     11521\n",
      "weighted avg       0.95      0.94      0.94     11521\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.metrics import f1_score, classification_report, confusion_matrix\n",
    "\n",
    "naive_bayes = BernoulliNB()\n",
    "\n",
    "naive_bayes.fit(X_train.toarray(), y_train)\n",
    "\n",
    "y_pred_train_nb = naive_bayes.predict(X_train.toarray())\n",
    "y_pred_test_nb = naive_bayes.predict(X_test.toarray())\n",
    "\n",
    "accuracy_train_nb = naive_bayes.score(X_train.toarray(), y_train)\n",
    "accuracy_test_nb = naive_bayes.score(X_test.toarray(), y_test)\n",
    "\n",
    "print(f\"Train Accuracy: {accuracy_train_nb}\")\n",
    "print(f\"Test Accuracy: {accuracy_test_nb}\")\n",
    "\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_test_nb)}\")\n",
    "print(classification_report(y_test, y_pred_test_nb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9491124517165054\n",
      "Test Accuracy: 0.9477475913549172\n",
      "F1 Score: 0.9729486833827626\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.14      0.24       648\n",
      "           1       0.95      1.00      0.97     10873\n",
      "\n",
      "    accuracy                           0.95     11521\n",
      "   macro avg       0.81      0.57      0.60     11521\n",
      "weighted avg       0.94      0.95      0.93     11521\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = LogisticRegression()\n",
    "\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred_train_lr = log_reg.predict(X_train)\n",
    "y_pred_test_lr = log_reg.predict(X_test)\n",
    "\n",
    "accuracy_train_lr = log_reg.score(X_train, y_train)\n",
    "accuracy_test_lr = log_reg.score(X_test, y_test)\n",
    "\n",
    "print(f\"Train Accuracy: {accuracy_train_lr}\")\n",
    "print(f\"Test Accuracy: {accuracy_test_lr}\")\n",
    "\n",
    "print(f\"F1 Score: {f1_score(y_test, y_pred_test_lr)}\")\n",
    "print(classification_report(y_test, y_pred_test_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.19.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (4.0 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.2.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.71.0-cp312-cp312-macosx_10_14_universal2.whl.metadata (3.8 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Downloading keras-3.9.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /opt/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.1-cp312-cp312-macosx_10_9_universal2.whl.metadata (21 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/anaconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in /opt/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Downloading optree-0.14.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (49 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/anaconda3/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.19.0-cp312-cp312-macosx_12_0_arm64.whl (252.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m252.7/252.7 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-2.2.1-py3-none-any.whl (277 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.71.0-cp312-cp312-macosx_10_14_universal2.whl (11.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.9.1-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.1-cp312-cp312-macosx_10_9_universal2.whl (670 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.4/670.4 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.14.1-cp312-cp312-macosx_11_0_arm64.whl (339 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt-einsum, ml-dtypes, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "Successfully installed absl-py-2.2.1 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 keras-3.9.1 libclang-18.1.1 ml-dtypes-0.5.1 namex-0.0.8 opt-einsum-3.4.0 optree-0.14.1 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 termcolor-2.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 122ms/step - accuracy: 0.9385 - loss: 0.2513 - val_accuracy: 0.9446 - val_loss: 0.2143\n",
      "Epoch 2/5\n",
      "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 130ms/step - accuracy: 0.9449 - loss: 0.2285 - val_accuracy: 0.9446 - val_loss: 0.2152\n",
      "Epoch 3/5\n",
      "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 135ms/step - accuracy: 0.9433 - loss: 0.2296 - val_accuracy: 0.9446 - val_loss: 0.2147\n",
      "Epoch 4/5\n",
      "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m158s\u001b[0m 137ms/step - accuracy: 0.9424 - loss: 0.2283 - val_accuracy: 0.9446 - val_loss: 0.2142\n",
      "Epoch 5/5\n",
      "\u001b[1m1153/1153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 138ms/step - accuracy: 0.9449 - loss: 0.2196 - val_accuracy: 0.9446 - val_loss: 0.2151\n",
      "\u001b[1m361/361\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 40ms/step - accuracy: 0.9450 - loss: 0.2139\n",
      "Test Loss: 0.21752749383449554\n",
      "Test Accuracy: 0.9437549114227295\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "X_train_reshaped = X_train.toarray().reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "X_test_reshaped = X_test.toarray().reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "\n",
    "model = Sequential([\n",
    "    LSTM(128, return_sequences=True, input_shape=(X_train_reshaped.shape[1], 1)),\n",
    "    LSTM(64, return_sequences=True),\n",
    "    LSTM(32),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_reshaped, y_train, epochs=5, batch_size=32, validation_split=0.2)\n",
    "\n",
    "loss, accuracy = model.evaluate(X_test_reshaped, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
